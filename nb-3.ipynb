{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/retowuest/uib-dl-2024/blob/main/nb-3.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning for Social Scientists\n",
    "\n",
    "### PhD Course, University of Bergen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Notebook 3:**<br>Convolutional Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "* [Introduction](#section_1)\n",
    "* [Loading the Data](#section_2)\n",
    "* [Data Augmentation](#section_3)\n",
    "* [TBA](#section_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction <a class=\"anchor\" id=\"section_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will use [PyTorch](https://pytorch.org/) to build a convolutional neural network (CNN) for smile classification of face images. We will distinguish between *smile* and *not smile*, so this is a binary classification task.\n",
    "\n",
    "We will use the **CelebA** data set provided by [Torchvision](https://pytorch.org/vision/stable/index.html). Information about this data set is available [here](https://pytorch.org/vision/stable/datasets.html#celeba). The data set contains 202,599 images of celebrities' faces. It also contains 40 binary facial attributes for each image, including whether a celebrity is smiling or not.\n",
    "\n",
    "Our goal is to build and train a CNN model for predicting the smile attribute from the face images. For simplicity, we will only be using a small portion of the training data (16,000 training examples) to speed up the training process. However, to reduce overfitting on such a small data set and improve generalization performance, we will use a technique called [data augmentation](https://en.wikipedia.org/wiki/Data_augmentation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data <a class=\"anchor\" id=\"section_2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first load the data. The **CelebA** data comes in three partitions: a training set, a validation set, and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import torchvision library\n",
    "import torchvision\n",
    "\n",
    "# Set the root of the folder containing the data\n",
    "image_path = \"./\"\n",
    "\n",
    "# Load train, validation, and test sets\n",
    "# (if you download the files with torchvision,\n",
    "# set download=True in the below code snippets)\n",
    "celeba_train = torchvision.datasets.CelebA(\n",
    "    image_path, split=\"train\",\n",
    "    target_type=\"attr\", download=False\n",
    ")\n",
    "\n",
    "celeba_valid = torchvision.datasets.CelebA(\n",
    "    image_path, split=\"valid\",\n",
    "    target_type=\"attr\", download=False\n",
    ")\n",
    "\n",
    "celeba_test = torchvision.datasets.CelebA(\n",
    "    image_path, split=\"test\",\n",
    "    target_type=\"attr\", download=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's count the number of examples in each partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 162770\n",
      "Validation set: 19867\n",
      "Test set: 19962\n"
     ]
    }
   ],
   "source": [
    "# Count number of examples in each partition\n",
    "print(\"Train set:\", len(celeba_train))\n",
    "print(\"Validation set:\", len(celeba_valid))\n",
    "print(\"Test set:\", len(celeba_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation <a class=\"anchor\" id=\"section_3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data augmentation summarizes a set of techniques we can use to deal with cases where the training data are limited. For example, data augmentation techniques allow us to modify data, or even artificially synthesize more data, and thereby improve the performance of a machine learning or deep learning model by reducing overfitting. For our image data, we will employ five different types of transformations available from the `torchvision.transforms` module:\n",
    "- cropping an image to a bounding box;\n",
    "- flipping an image horizontally;\n",
    "- adjusting the contrast;\n",
    "- adjusting the brightness;\n",
    "- center-cropping an image and resizing the resulting image back to its original size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
